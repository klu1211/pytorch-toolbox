{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to see if we can decrease the training time between experiments. We do this by using only a subset of the external data set then we will use the external dataset and the internal validation dataset to see the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "from src.data import DataPaths\n",
    "from src.data import single_class_counter\n",
    "\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at the distribution of the labels bewteen both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_df = pd.read_csv(DataPaths.TRAIN_ALL_LABELS)\n",
    "all_labels_df['Target'] = [[int(i) for i in s.split()] for s in all_labels_df['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa_labels_df = pd.read_csv(DataPaths.TRAIN_HPA_V18_LABELS)\n",
    "hpa_labels_df['Target'] = [[int(i) for i in s.split()] for s in hpa_labels_df['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 0.0003679981775328351),\n",
      " (24, 0.0009287573052019171),\n",
      " (27, 0.0010163759189002113),\n",
      " (9, 0.0013318029282140698),\n",
      " (10, 0.0013493266509537285),\n",
      " (8, 0.0014369452646520228),\n",
      " (17, 0.00206779928327974),\n",
      " (20, 0.002330655124374622),\n",
      " (26, 0.003311983597795516),\n",
      " (16, 0.006659014641070349),\n",
      " (13, 0.008069674321612883),\n",
      " (18, 0.008683004617500942),\n",
      " (11, 0.009646809368182177),\n",
      " (12, 0.013537075816386433),\n",
      " (14, 0.014246786587342615),\n",
      " (3, 0.015490970901858392),\n",
      " (1, 0.01592906397034986),\n",
      " (22, 0.016884106859661265),\n",
      " (19, 0.0191884763999264),\n",
      " (6, 0.023805977341826497),\n",
      " (4, 0.02866881040208182),\n",
      " (5, 0.030009375191665716),\n",
      " (7, 0.05767933339758698),\n",
      " (2, 0.06352349493126319),\n",
      " (23, 0.06466253690934103),\n",
      " (21, 0.0878989932621286),\n",
      " (0, 0.24597173423522092),\n",
      " (25, 0.2553031165940893)]\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(single_class_counter(hpa_labels_df['Target'].values), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_labels_df = pd.read_csv(DataPaths.TRAIN_LABELS)\n",
    "kaggle_labels_df['Target'] = [[int(i) for i in s.split()] for s in kaggle_labels_df['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(27, 0.0002166121854200307),\n",
      " (15, 0.000413532353983695),\n",
      " (10, 0.00055137647197826),\n",
      " (9, 0.0008861407585364893),\n",
      " (8, 0.0010436768933874208),\n",
      " (20, 0.0033870268992950256),\n",
      " (17, 0.00413532353983695),\n",
      " (24, 0.00634082942774999),\n",
      " (26, 0.006458981528888188),\n",
      " (16, 0.010436768933874208),\n",
      " (13, 0.010574613051868773),\n",
      " (12, 0.013548107597180102),\n",
      " (22, 0.015792997518805876),\n",
      " (18, 0.017762199204442518),\n",
      " (6, 0.01984955299121736),\n",
      " (14, 0.020991689968886614),\n",
      " (11, 0.021523374424008507),\n",
      " (1, 0.0246937891378835),\n",
      " (19, 0.029183568981135048),\n",
      " (3, 0.030739238312787995),\n",
      " (4, 0.03658776731912883),\n",
      " (5, 0.049486038360048834),\n",
      " (7, 0.05557087156866606),\n",
      " (23, 0.05838682997912646),\n",
      " (2, 0.07130479303690283),\n",
      " (21, 0.074376747666496),\n",
      " (25, 0.16202591469418298),\n",
      " (0, 0.25373163719428143)]\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(single_class_counter(kaggle_labels_df['Target'].values), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multi_class_counter(labels):\n",
    "# sorted(Counter(tuple(l) for l in kaggle_labels_df['Target'].values).items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we decide what to set the threshold as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_training_examples(kaggle_labels_df, hpa_labels_df, threshold=0.02):\n",
    "    include_below = 0.02\n",
    "    included_labels = []\n",
    "    for label, proportion in sorted(single_class_counter(kaggle_labels_df['Target'].values), key=lambda x: x[1]):\n",
    "        if proportion < include_below:\n",
    "            included_labels.append(label)\n",
    "    rare_labels_from_hpa_df = hpa_labels_df[hpa_labels_df['Target'].map(lambda x: len(set(x) & set(included_labels)) > 0)]\n",
    "    combined_training_df = pd.concat([kaggle_labels_df, rare_labels_from_hpa_df])\n",
    "    return combined_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.02\n",
    "combined_training_df = create_combined_training_examples(kaggle_labels_df, hpa_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40815, 2)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(sorted(single_class_counter(combined_training_df['Target'].values), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = list(set(hpa_labels_df['Id'].values) - set(combined_training_df['Id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_val_df = all_labels_df[all_labels_df['Id'].isin(val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64863, 2)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the label csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/pytorch-toolbox/lib/python3.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "combined_training_df['Target'] = combined_training_df['Target'].map(lambda x: \" \".join(str(i) for i in x))\n",
    "combined_val_df['Target'] = combined_val_df['Target'].map(lambda x: \" \".join(str(i) for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31090</th>\n",
       "      <td>11651_1601_F3_3</td>\n",
       "      <td>23 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31091</th>\n",
       "      <td>11651_1601_F3_4</td>\n",
       "      <td>23 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31092</th>\n",
       "      <td>11651_1611_B3_2</td>\n",
       "      <td>23 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31093</th>\n",
       "      <td>11651_1611_B3_3</td>\n",
       "      <td>23 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31094</th>\n",
       "      <td>11651_1732_F3_13_cr580610dc203b9</td>\n",
       "      <td>23 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id Target\n",
       "31090                   11651_1601_F3_3   23 0\n",
       "31091                   11651_1601_F3_4   23 0\n",
       "31092                   11651_1611_B3_2   23 0\n",
       "31093                   11651_1611_B3_3   23 0\n",
       "31094  11651_1732_F3_13_cr580610dc203b9   23 0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training_df.to_csv(DataPaths.TRAIN_HPA_KAGGLE_THRESH_0_02_LABELS, index=False)\n",
    "combined_val_df.to_csv(DataPaths.VAL_HPA_KAGGLE_THRESH_0_02_LABELS, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate the soft links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = combined_training_df['Id'].values\n",
    "training_images_folder = DataPaths.TRAIN_HPA_KAGGLE_THRESH_0_02_COMBINED_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = combined_val_df['Id'].values\n",
    "val_images_folder = DataPaths.VAL_HPA_KAGGLE_THRESH_0_02_COMBINED_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_soft_links(source_images_folder, dest_images_folder, dest_images_id):\n",
    "    dest_images_folder.mkdir(exist_ok=True, parents=True)\n",
    "    id_lookups = Counter(dest_images_id)\n",
    "    for p in source_images_folder.glob(\"*\"):\n",
    "        if id_lookups.get(p.stem) is not None:\n",
    "            os.symlink(src=p, dst=dest_images_folder / p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../../data/train_all_combined/711f1d5e-bbb2-11e8-b2ba-ac1f6b6435d0.npy' -> '../../data/train_hpa_kaggle_thresh_0_02/711f1d5e-bbb2-11e8-b2ba-ac1f6b6435d0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-0890f03cca9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_soft_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataPaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_ALL_COMBINED_IMAGES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_images_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-187-828c67fb7b1e>\u001b[0m in \u001b[0;36mgenerate_soft_links\u001b[0;34m(source_images_folder, dest_images_folder, dest_images_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_images_folder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid_lookups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest_images_folder\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '../../data/train_all_combined/711f1d5e-bbb2-11e8-b2ba-ac1f6b6435d0.npy' -> '../../data/train_hpa_kaggle_thresh_0_02/711f1d5e-bbb2-11e8-b2ba-ac1f6b6435d0.npy'"
     ]
    }
   ],
   "source": [
    "generate_soft_links(DataPaths.TRAIN_ALL_COMBINED_IMAGES, training_images_folder, train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_soft_links(DataPaths.TRAIN_ALL_COMBINED_IMAGES, val_images_folder, val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
